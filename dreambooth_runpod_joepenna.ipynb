{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2c1ada",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Dreambooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946694e-edd0-4225-90cc-b4de9f177907",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace/Person-Plus-Style-Stable-Diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b19197-540d-4820-9be3-ac7566a1b7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25b19e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf\n",
    "!pip install gdown\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install huggingface_hub\n",
    "!pip install captionizer==1.0.1\n",
    "!pip install Pillow\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a5ef8",
   "metadata": {},
   "source": [
    "# Download the 1.5 model from hugging face\n",
    "You can also provide your own v1.* model for training by uploading it and renaming it to \"model.ckpt\".  It should be in the same directory as dreambooth_runpod_joepenna.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480ca04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download the 1.5 sd model\n",
    "from IPython.display import clear_output\n",
    "from huggingface_hub import hf_hub_download\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "download_ckpt = False\n",
    "\n",
    "if download_ckpt:\n",
    "  downloaded_model_path = hf_hub_download(\n",
    "    repo_id=\"PiyarSquare/sd_asim_simpsons\",\n",
    "    filename=\"asim_v1.ckpt\"\n",
    "  )\n",
    "  actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "  !mv {actual_locations_of_model_blob[-1]} model\n",
    "else:\n",
    "  # !rm -rf model/\n",
    "  # !mkdir model/\n",
    "  downloaded_model_path = snapshot_download(\n",
    "    repo_id=\"lambdalabs/sd-naruto-diffusers\",\n",
    "    local_dir=\"model/\"\n",
    "  )\n",
    "\n",
    "  !python scripts/convert_to_ckpt.py \\\n",
    "   --model_path=\"/workspace/Person-Plus-Style-Stable-Diffusion/model/\" \\\n",
    "   --checkpoint_path=\"/workspace/Person-Plus-Style-Stable-Diffusion/model.ckpt\"\n",
    "\n",
    "# clear_output()\n",
    "\n",
    "print(\"âœ… model.ckpt successfully downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef8087",
   "metadata": {},
   "source": [
    "# Download pre-generated regularization images\n",
    "We've created the following image sets\n",
    "\n",
    "* `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
    "* `man_unsplash` - pictures from various photographers\n",
    "* `person_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0\n",
    "* `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0\n",
    "* `artstyle` - provided by Hackmans - ddim @ 50 steps, CFG 10.0\n",
    "\n",
    "`person_ddim` is recommended for training people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"artstyle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7EydXCjOV1v",
   "metadata": {
    "id": "e7EydXCjOV1v"
   },
   "outputs": [],
   "source": [
    "#Download Regularization Images\n",
    "\n",
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "\n",
    "# rename images & hide output\n",
    "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset} > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23829405-4faf-4bdb-969a-52d5e82a6d89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Upload your training images\n",
    "Upload 10-20 images of someone to\n",
    "\n",
    "```\n",
    "/workspace/Person-Plus-Style-Stable-Diffusion/training_images\n",
    "```\n",
    "\n",
    "WARNING: Be sure to upload an *even* amount of images, otherwise the training inexplicably stops at 1500 steps.\n",
    "\n",
    "*   2-3 full body\n",
    "*   3-5 upper body\n",
    "*   5-12 close-up on face\n",
    "\n",
    "The images should be:\n",
    "\n",
    "- as close as possible to the kind of images you're trying to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df643c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir training_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2270851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download and check the images you have just added\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from scripts.smart_crop import *\n",
    "\n",
    "# crop images\n",
    "\n",
    "for filename in os.listdir(\"training_images\"):\n",
    "    extension = filename.split(\".\")[-1].lower()\n",
    "    extension = extension.lower()\n",
    "    \n",
    "    if extension != \"jpg\" and extension != \"jpeg\" and extension != \"png\":\n",
    "        continue\n",
    "\n",
    "    identifier = filename.split(\".\")[0]\n",
    "    new_path_with_file = os.path.join(\"training_images\", identifier + \".\" + extension)\n",
    "    file = Image.open(\"training_images\" + \"/\" + filename)\n",
    "    width, height = file.size\n",
    "\n",
    "    if file.size != (512, 512):\n",
    "        image = crop_image(file, 512)\n",
    "\n",
    "        if extension == \"jpeg\" or extension == \"jpg\":\n",
    "            image[0] = image[0].convert(\"RGB\")\n",
    "            image[0].save(new_path_with_file, format = \"JPEG\", quality = 100)\n",
    "        else:\n",
    "            image[0].save(new_path_with_file, format = extension.upper())\n",
    "    \n",
    "    print(filename + \" is 512x512px now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e50df",
   "metadata": {
    "id": "ad4e50df"
   },
   "source": [
    "## Training\n",
    "\n",
    "If training a person or subject, keep an eye on your project's `logs/{folder}/images/train/samples_scaled_gs-00xxxx` generations.\n",
    "\n",
    "If training a style, keep an eye on your project's `logs/{folder}/images/train/samples_gs-00xxxx` generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# This isn't used for training, just to help you remember what your trained into the model.\n",
    "project_name = \"asimrhaenyra\"\n",
    "\n",
    "# MAX STEPS\n",
    "# How many steps do you want to train for?\n",
    "max_training_steps = 1010\n",
    "\n",
    "# Match class_word to the category of the regularization images you chose above.\n",
    "class_word = \"person\" # typical uses are \"man\", \"person\", \"woman\"\n",
    "\n",
    "# If you are training a person's face, set this to True\n",
    "i_am_training_a_persons_face = True\n",
    "\n",
    "flip_p_arg = 0.0 if i_am_training_a_persons_face else 0.5\n",
    "\n",
    "# This is the unique token you are incorporating into the stable diffusion model.\n",
    "token = \"asimrhaenyra\"\n",
    "\n",
    "# 0 Saves the checkpoint when max_training_steps is reached.\n",
    "# 250 saves the checkpoint every 250 steps as well as when max_training_steps is reached.\n",
    "save_every_x_steps = 0\n",
    "\n",
    "reg_data_root = \"/workspace/Person-Plus-Style-Stable-Diffusion/regularization_images/\" + dataset\n",
    "\n",
    "!rm -rf training_images/.ipynb_checkpoints\n",
    "!python \"main.py\" \\\n",
    " --base \"configs/stable-diffusion/v1-finetune_unfrozen.yaml\" \\\n",
    " -t \\\n",
    " --actual_resume \"model.ckpt\" \\\n",
    " --reg_data_root \"{reg_data_root}\" \\\n",
    " -n \"{project_name}\" \\\n",
    " --gpus 0, \\\n",
    " --data_root \"/workspace/Person-Plus-Style-Stable-Diffusion/training_images\" \\\n",
    " --max_training_steps {max_training_steps} \\\n",
    " --class_word \"{class_word}\" \\\n",
    " --token \"{token}\" \\\n",
    " --no-test \\\n",
    " --flip_p {flip_p_arg} \\\n",
    " --save_every_x_steps {save_every_x_steps}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49d0bd",
   "metadata": {},
   "source": [
    "## Copy and name the checkpoint file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde83ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "training_images = !find training_images/*\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "\n",
    "if save_every_x_steps == 0:\n",
    " # Copy the checkpoint into our `trained_models` folder\n",
    " directory_paths = !ls -d logs/*\n",
    " last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    " file_name = date_string[-1] + \"_\" + \\\n",
    "             project_name + \"_\" + \\\n",
    "             str(len(training_images)) + \"_training_images_\" + \\\n",
    "             str(max_training_steps) + \"_max_training_steps_\" + \\\n",
    "             token + \"_token_\" + \\\n",
    "             class_word + \"_class_word.ckpt\"\n",
    "\n",
    " file_name = file_name.replace(\" \", \"_\")\n",
    "\n",
    " !mkdir -p trained_models\n",
    " !mv {last_checkpoint_file} trained_models/{file_name}\n",
    "\n",
    " print(\"Download your trained model from trained_models/\" + file_name + \" and use in your favorite Stable Diffusion repo!\")\n",
    "else:\n",
    " directory_paths = !ls -d logs/*\n",
    " checkpoints_directory = directory_paths[-1] + \"/checkpoints/trainstep_checkpoints\"\n",
    " file_paths = !ls -d \"{checkpoints_directory}\"/*\n",
    "\n",
    " for i, original_file_name in enumerate(file_paths):\n",
    "  # Remove the \"epoch=000000-step=0000\" text\n",
    "  steps = re.sub(checkpoints_directory + \"/epoch=\\d{6}-step=0*\", \"\", original_file_name)\n",
    "\n",
    "  # Remove the .ckpt\n",
    "  steps = steps.replace(\".ckpt\", \"\")\n",
    "\n",
    "  # Setup the filename\n",
    "  file_name = date_string[-1] + \"_\" + \\\n",
    "                  project_name + \"_\" + \\\n",
    "                  str(len(training_images)) + \"_training_images_\" + \\\n",
    "                  str(steps) + \"_training_steps_\" + \\\n",
    "                  token + \"_token_\" + \\\n",
    "                  class_word + \"_class_word.ckpt\"\n",
    "\n",
    "  file_name = file_name.replace(\" \", \"_\")\n",
    "\n",
    "  # Make the directory and move the files into it.\n",
    "  !mkdir -p trained_models\n",
    "  !mv {original_file_name} trained_models/{file_name}\n",
    "\n",
    " print(\"Download your trained models from the 'trained_models' folder and use in your favorite Stable Diffusion repo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90ac5c",
   "metadata": {},
   "source": [
    "# Big Important Note!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d28d0139",
   "metadata": {},
   "source": [
    " asim style. dramatic beautiful { headshot | portrait } of __person__ {outside { in a garden | in a desert | on a mountain top | at a roman ruin} {at sunrise | at sunset | on an overcast afternoon | in the rain | in the snow | at night} | inside {a fancy living room | on a movie set | a vast empty dark space | a kaleidoscope | an ancient library} with {spotlights | neon lights | soft mood lighting | firefly lights } }. detailed background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prompt = 'portrait of {token} {class_word} in ((naruto style)), detailed eyes, outside in a garden at sunset with soft mood lighting'\n",
    "neg_prompt = 'watermark, text, signature'\n",
    "\n",
    "for steps in range(20, 100, 10):\n",
    "    for _scale in range(30, 121, 5):\n",
    "        scale = float(_scale / 10)\n",
    "        print(f\"steps = {steps}, scale = {scale}\")\n",
    "        os.system(f\"python scripts/stable_txt2img.py --ddim_eta 0.0 --n_samples 1 --n_iter 4 --scale {scale} --ddim_steps {steps} --ckpt '/workspace/Person-Plus-Style-Stable-Diffusion/trained_models/{file_name}' --prompt '{prompt}' --negative_prompt '{neg_prompt}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ddb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter 4 \\\n",
    " --scale 6.5 \\\n",
    " --ddim_steps 20 \\\n",
    " --ckpt \"/workspace/Person-Plus-Style-Stable-Diffusion/trained_models/{file_name}\" \\\n",
    " --prompt \"portrait of {token} {class_word} in ((naruto style)), detailed eyes, outside in a garden at sunset with soft mood lighting\" \\\n",
    " --negative_prompt \"watermark, text, signature, cross-eyed\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b44ff44089365a11200b1d91e09ac4b6d525418400c6dcc6ca005771efff825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
